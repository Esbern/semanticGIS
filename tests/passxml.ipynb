{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e3f0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlhome = \"https://grunddatamodel.datafordeler.dk/domaenemodeller/\"\n",
    "xmlfolder = \"/Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b64800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No XML versions found for root, skipping.\n",
      "Downloaded 2.4.2_BygningerOgBoliger.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/BygningerOgBoliger/2.4.2_BygningerOgBoliger.xml\n",
      "Downloaded 2.2.0_CentraleVirksomhedsregister.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/CentraleVirksomhedsregister/2.2.0_CentraleVirksomhedsregister.xml\n",
      "Downloaded 2.0.0_DAGI.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/DAGI/2.0.0_DAGI.xml\n",
      "Downloaded 2.0.2_DanmarksAdresser.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/DanmarksAdresser/2.0.2_DanmarksAdresser.xml\n",
      "Downloaded 1.2.1_DHMOprindelse.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/DHMOprindelse/1.2.1_DHMOprindelse.xml\n",
      "Downloaded 1.3.0_Ejendomsbeliggenhed.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Ejendomsbeliggenhed/1.3.0_Ejendomsbeliggenhed.xml\n",
      "Downloaded 1.1.3_Ejendomsvurdering.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Ejendomsvurdering/1.1.3_Ejendomsvurdering.xml\n",
      "Downloaded 1.3.2_Ejerfortegnelsen.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Ejerfortegnelsen/1.3.2_Ejerfortegnelsen.xml\n",
      "Downloaded 1.0.6_Fikspunkt.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Fikspunkter/1.0.6_Fikspunkt.xml\n",
      "Downloaded 2.0.1_GeoDanmark.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/GeoDanmark/2.0.1_GeoDanmark.xml\n",
      "Downloaded 1.0.0_Grunddata.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/GrunddataTyper/1.0.0_Grunddata.xml\n",
      "Downloaded 1.1.2_HistoriskeKortbladsinddelinger.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/HistoriskeKortbladsinddelinger/1.1.2_HistoriskeKortbladsinddelinger.xml\n",
      "Downloaded 1.0.1_Højdekurver.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Højdekurver/1.0.1_Højdekurver.xml\n",
      "Downloaded 2.0.1_Matrikel.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Matrikel/2.0.1_Matrikel.xml\n",
      "Downloaded 2.1.1_Person.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Person/2.1.1_Person.xml\n",
      "Downloaded 1.0.0_SkatteforvaltningensVirksomhedsregister.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/SkatteforvaltningensVirksomhedsregister/1.0.0_SkatteforvaltningensVirksomhedsregister.xml\n",
      "Downloaded 1.0.1_Stednavne.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Stednavne/1.0.1_Stednavne.xml\n",
      "Fetched latest XML for 17 registers.\n"
     ]
    }
   ],
   "source": [
    "from html.parser import HTMLParser\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin, unquote\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "\n",
    "class _LinkCollector(HTMLParser):\n",
    "    \"\"\"Collects href targets from the simple directory listings.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.links: list[str] = []\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag != \"a\":\n",
    "            return\n",
    "        href = dict(attrs).get(\"href\")\n",
    "        if href:\n",
    "            self.links.append(href)\n",
    "\n",
    "\n",
    "def _list_links(url: str) -> list[str]:\n",
    "    with urlopen(url) as response:\n",
    "        html = response.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "    parser = _LinkCollector()\n",
    "    parser.feed(html)\n",
    "    return parser.links\n",
    "\n",
    "\n",
    "def _version_key(filename: str):\n",
    "    name = Path(filename).name\n",
    "    if not name.lower().endswith(\".xml\") or \"_\" not in name:\n",
    "        return None\n",
    "    version_candidate = name.split(\"_\", 1)[0]\n",
    "    if not re.fullmatch(r\"\\d+(?:\\.\\d+)*\", version_candidate):\n",
    "        return None\n",
    "    return tuple(int(part) for part in version_candidate.split(\".\"))\n",
    "\n",
    "\n",
    "def _latest_xml(register_url: str):\n",
    "    candidates = []\n",
    "    for href in _list_links(register_url):\n",
    "        if not href.lower().endswith(\".xml\") or \"?\" in href:\n",
    "            continue\n",
    "        version = _version_key(href)\n",
    "        if version is None:\n",
    "            continue\n",
    "        candidates.append((version, href))\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda item: item[0], reverse=True)\n",
    "    return candidates[0][1]\n",
    "\n",
    "\n",
    "base_url = xmlhome.rstrip(\"/\") + \"/\"\n",
    "output_root = Path(xmlfolder)\n",
    "output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "register_dirs = [\n",
    "    href for href in _list_links(base_url) if href.endswith(\"/\") and href not in {\"../\", \"./\"}\n",
    " ]\n",
    "\n",
    "completed = []\n",
    "for href in register_dirs:\n",
    "    register_url = urljoin(base_url, href)\n",
    "    decoded_href = unquote(href.strip(\"/\"))\n",
    "    register_name = Path(decoded_href).name or \"root\"\n",
    "    try:\n",
    "        latest_file = _latest_xml(register_url)\n",
    "    except Exception as exc:\n",
    "        print(f\"Failed to inspect {register_name}: {exc}\")\n",
    "        continue\n",
    "    if not latest_file:\n",
    "        print(f\"No XML versions found for {register_name}, skipping.\")\n",
    "        continue\n",
    "    download_url = urljoin(register_url, latest_file)\n",
    "    destination_dir = output_root / register_name\n",
    "    destination_dir.mkdir(parents=True, exist_ok=True)\n",
    "    file_name = unquote(Path(latest_file).name)\n",
    "    destination_path = destination_dir / file_name\n",
    "    try:\n",
    "        with urlopen(download_url) as response:\n",
    "            destination_path.write_bytes(response.read())\n",
    "        print(f\"Downloaded {file_name} to {destination_path}\")\n",
    "        completed.append(register_name)\n",
    "    except Exception as exc:\n",
    "        print(f\"Failed to download {register_name} ({latest_file}): {exc}\")\n",
    "\n",
    "if completed:\n",
    "    print(f\"Fetched latest XML for {len(completed)} registers.\")\n",
    "else:\n",
    "    print(\"No XML models downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2209db4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote summaries for 17 registers to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/class_summary.json\n",
      "BygningerOgBoliger: 12 classes / 1 abstract\n",
      "  - BBRSag (34 attrs) sag001Byggesagsnummer, sag002Byggesagsdato, sag003Byggetilladelsesdato\n",
      "  - Bygning (90 attrs) byg007Bygningsnummer, byg021BygningensAnvendelse, byg024AntalLejlighederMedKøkken\n",
      "  - Bygværkselement (12 attrs) forretningshændelse, forretningsområde, status\n",
      "\n",
      "CentraleVirksomhedsregister: 27 classes / 4 abstract\n",
      "  - AndenDeltager (11 attrs) personNavn, cvrAdresse, andenDeltagerType\n",
      "  - CVRAdresse (26 attrs) adresseFritekst, bogstav, bygningsnummer\n",
      "  - CVREnhed (8 attrs) id, registreringFra, registreringsaktør\n",
      "\n",
      "DAGI: 54 classes / 1 abstract\n",
      "  - AdministrativInddeling (11 attrs) id, navn, registreringFra\n",
      "  - Afstemningsområde (17 attrs) afstemningsområdenummer, afstemningsstedNavn, afstemningsstedAdresse\n",
      "  - Afstemningsområde_2000000 (17 attrs) afstemningsområdenummer, afstemningsstedNavn, afstemningsstedAdresse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def _tag_name(elem):\n",
    "    tag = elem.tag\n",
    "    if isinstance(tag, str):\n",
    "        if tag.startswith(\"{\") and \"}\" in tag:\n",
    "            return tag.split(\"}\", 1)[1]\n",
    "        if \":\" in tag:\n",
    "            return tag.split(\":\", 1)[1]\n",
    "    return tag\n",
    "\n",
    "\n",
    "def _attr(elem, name):\n",
    "    if name in elem.attrib:\n",
    "        return elem.attrib[name]\n",
    "    for key, value in elem.attrib.items():\n",
    "        if key.endswith(name):\n",
    "            return value\n",
    "        if \"}\" in key and key.split(\"}\", 1)[1] == name:\n",
    "            return value\n",
    "        if \":\" in key and key.split(\":\", 1)[1] == name:\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "\n",
    "def _xmi_type(elem):\n",
    "    for key in (\n",
    "        \"{http://www.omg.org/spec/XMI/20131001}type\",\n",
    "        \"{http://www.omg.org/spec/XMI/20110701}type\",\n",
    "        \"xmi:type\",\n",
    "    ):\n",
    "        if key in elem.attrib:\n",
    "            return elem.attrib[key]\n",
    "    for key, value in elem.attrib.items():\n",
    "        if key.endswith(\"}type\"):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "\n",
    "def _index_elements(root):\n",
    "    index = {}\n",
    "    for elem in root.iter():\n",
    "        elem_id = _attr(elem, \"id\")\n",
    "        if not elem_id or elem_id in index:\n",
    "            continue\n",
    "        index[elem_id] = {\n",
    "            \"name\": elem.attrib.get(\"name\"),\n",
    "            \"umlType\": elem.attrib.get(\"UMLType\")\n",
    "            or elem.attrib.get(\"umlType\")\n",
    "            or _xmi_type(elem)\n",
    "            or _tag_name(elem),\n",
    "            \"xmiType\": _xmi_type(elem),\n",
    "            \"tag\": _tag_name(elem),\n",
    "        }\n",
    "    return index\n",
    "\n",
    "\n",
    "def _version_tuple(filename: str) -> tuple[int, ...]:\n",
    "    candidate = Path(filename).stem.split(\"_\", 1)[0]\n",
    "    parts = []\n",
    "    for part in candidate.split(\".\"):\n",
    "        if not part.isdigit():\n",
    "            return ()\n",
    "        parts.append(int(part))\n",
    "    return tuple(parts)\n",
    "\n",
    "\n",
    "def _parse_attributes(class_elem, class_name, id_index):\n",
    "    attrs = []\n",
    "    for child in class_elem:\n",
    "        if _tag_name(child) != \"ownedAttribute\":\n",
    "            continue\n",
    "        attr_name = child.attrib.get(\"name\")\n",
    "        if not attr_name:\n",
    "            continue\n",
    "        attr_kind = _xmi_type(child) or _tag_name(child)\n",
    "        attr_id = _attr(child, \"id\")\n",
    "        type_ref = child.attrib.get(\"type\") or _attr(child, \"type\")\n",
    "        association_id = child.attrib.get(\"association\") or _attr(child, \"association\")\n",
    "        lower = child.attrib.get(\"lower\")\n",
    "        upper = child.attrib.get(\"upper\")\n",
    "        for grandchild in child:\n",
    "            tag = _tag_name(grandchild)\n",
    "            if tag == \"lowerValue\":\n",
    "                lower = grandchild.attrib.get(\"value\")\n",
    "            elif tag == \"upperValue\":\n",
    "                upper = grandchild.attrib.get(\"value\")\n",
    "            elif tag == \"type\":\n",
    "                type_ref = (\n",
    "                    _attr(grandchild, \"idref\")\n",
    "                    or grandchild.attrib.get(\"href\")\n",
    "                    or grandchild.attrib.get(\"value\")\n",
    "                    or type_ref\n",
    "                )\n",
    "        type_meta = id_index.get(type_ref or \"\")\n",
    "        type_name = type_meta.get(\"name\") if type_meta else None\n",
    "        type_uml = None\n",
    "        if type_meta:\n",
    "            type_uml = (\n",
    "                type_meta.get(\"umlType\")\n",
    "                or type_meta.get(\"xmiType\")\n",
    "                or type_meta.get(\"tag\")\n",
    "            )\n",
    "        lower_disp = lower if lower not in (None, \"\") else \"0\"\n",
    "        upper_disp = upper if upper not in (None, \"\", \"-1\") else \"*\"\n",
    "        attrs.append(\n",
    "            {\n",
    "                \"id\": attr_id,\n",
    "                \"name\": attr_name,\n",
    "                \"sourceClass\": class_name,\n",
    "                \"typeId\": type_ref,\n",
    "                \"typeName\": type_name,\n",
    "                \"typeUml\": type_uml,\n",
    "                \"type\": attr_kind,\n",
    "                \"lowerMultiplicity\": lower_disp,\n",
    "                \"upperMultiplicity\": upper_disp,\n",
    "                \"cardinality\": f\"{lower_disp}..{upper_disp}\",\n",
    "                \"associationId\": association_id,\n",
    "                \"isAssociation\": bool(association_id),\n",
    "                \"isForeignKey\": bool(association_id),\n",
    "            }\n",
    "        )\n",
    "    return attrs\n",
    "\n",
    "\n",
    "def _dedup_attributes(attributes):\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for attr in attributes:\n",
    "        key = (attr[\"name\"], attr.get(\"sourceClass\"))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        ordered.append(dict(attr))\n",
    "    return ordered\n",
    "\n",
    "\n",
    "def _collect_inherited(class_id, classes, memo, stack=None):\n",
    "    # Walk the generalization tree to gather inherited attributes once per class.\n",
    "    if class_id in memo:\n",
    "        return [dict(attr) for attr in memo[class_id]]\n",
    "    if stack is None:\n",
    "        stack = set()\n",
    "    if class_id in stack:\n",
    "        return []\n",
    "    stack.add(class_id)\n",
    "    inherited = []\n",
    "    for parent_id in classes.get(class_id, {}).get(\"parents\", []):\n",
    "        parent = classes.get(parent_id)\n",
    "        if not parent:\n",
    "            continue\n",
    "        inherited.extend(dict(attr) for attr in parent[\"ownAttributes\"])\n",
    "        inherited.extend(_collect_inherited(parent_id, classes, memo, stack))\n",
    "    stack.remove(class_id)\n",
    "    memo[class_id] = _dedup_attributes(inherited)\n",
    "    return [dict(attr) for attr in memo[class_id]]\n",
    "\n",
    "\n",
    "def _find_register_package(root):\n",
    "    for elem in root:\n",
    "        if _tag_name(elem) != \"Model\":\n",
    "            continue\n",
    "        for child in elem:\n",
    "            if _tag_name(child) == \"packagedElement\" and _xmi_type(child) == \"uml:Package\":\n",
    "                return _attr(child, \"id\"), child.attrib.get(\"name\")\n",
    "        break\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _summarize_collection(xml_path, register_name):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    id_index = _index_elements(root)\n",
    "    register_package_id, register_package_name = _find_register_package(root)\n",
    "\n",
    "    classes = {}\n",
    "    for elem in root.iter():\n",
    "        if _tag_name(elem) != \"packagedElement\":\n",
    "            continue\n",
    "        if _xmi_type(elem) != \"uml:Class\":\n",
    "            continue\n",
    "        class_id = _attr(elem, \"id\")\n",
    "        if not class_id:\n",
    "            continue\n",
    "        class_name = elem.attrib.get(\"name\") or class_id\n",
    "        parents = []\n",
    "        for child in elem:\n",
    "            if _tag_name(child) == \"generalization\":\n",
    "                parent_id = _attr(child, \"general\")\n",
    "                if parent_id:\n",
    "                    parents.append(parent_id)\n",
    "        classes[class_id] = {\n",
    "            \"id\": class_id,\n",
    "            \"name\": class_name,\n",
    "            \"isAbstract\": (_attr(elem, \"isAbstract\") or \"\").lower() in {\"true\", \"1\"},\n",
    "            \"parents\": parents,\n",
    "            \"ownAttributes\": _parse_attributes(elem, class_name, id_index),\n",
    "        }\n",
    "\n",
    "    inheritance_cache = {}\n",
    "    class_entries = []\n",
    "    for class_id, class_info in sorted(classes.items(), key=lambda item: item[1][\"name\"]):\n",
    "        inherited = _collect_inherited(class_id, classes, inheritance_cache, set())\n",
    "        own_attrs = [dict(attr) for attr in class_info[\"ownAttributes\"]]\n",
    "        all_attrs = _dedup_attributes(own_attrs + inherited)\n",
    "        class_entries.append(\n",
    "            {\n",
    "                \"id\": class_id,\n",
    "                \"register\": register_name,\n",
    "                \"name\": class_info[\"name\"],\n",
    "                \"isAbstract\": class_info[\"isAbstract\"],\n",
    "                \"ownAttributes\": own_attrs,\n",
    "                \"inheritedAttributes\": inherited,\n",
    "                \"attributes\": all_attrs,\n",
    "                \"attributeCount\": len(all_attrs),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    abstract_names = sorted(\n",
    "        class_info[\"name\"]\n",
    "        for class_info in classes.values()\n",
    "        if class_info[\"isAbstract\"]\n",
    "    )\n",
    "    register_package = None\n",
    "    if register_package_id or register_package_name:\n",
    "        register_package = {\n",
    "            \"id\": register_package_id,\n",
    "            \"name\": register_package_name,\n",
    "        }\n",
    "    return {\n",
    "        \"xmlFile\": xml_path.name,\n",
    "        \"registerPackage\": register_package,\n",
    "        \"classes\": class_entries,\n",
    "        \"abstractClasses\": abstract_names,\n",
    "    }\n",
    "\n",
    "\n",
    "root_dir = Path(xmlfolder)\n",
    "if not root_dir.exists():\n",
    "    raise FileNotFoundError(f\"XML folder not found: {root_dir}\")\n",
    "\n",
    "collection_summaries = {}\n",
    "for register_dir in sorted((p for p in root_dir.iterdir() if p.is_dir()), key=lambda p: p.name):\n",
    "    xml_files = sorted(\n",
    "        register_dir.glob(\"*.xml\"),\n",
    "        key=lambda path: (_version_tuple(path.name), path.name),\n",
    "    )\n",
    "    if not xml_files:\n",
    "        continue\n",
    "    xml_path = xml_files[-1]\n",
    "    try:\n",
    "        collection_summaries[register_dir.name] = _summarize_collection(xml_path, register_dir.name)\n",
    "    except Exception as exc:\n",
    "        print(f\"Failed to summarize {xml_path}: {exc}\")\n",
    "\n",
    "if not collection_summaries:\n",
    "    print(f\"No XML models found under {root_dir}\")\n",
    "else:\n",
    "    summary_path = root_dir / \"class_summary.json\"\n",
    "    summary_path.write_text(\n",
    "        json.dumps(collection_summaries, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    print(f\"Wrote summaries for {len(collection_summaries)} registers to {summary_path}\")\n",
    "\n",
    "    preview_count = 3\n",
    "    for register_name in list(collection_summaries)[:preview_count]:\n",
    "        info = collection_summaries[register_name]\n",
    "        print(\n",
    "            f\"{register_name}: {len(info['classes'])} classes / \"\n",
    "            f\"{len(info['abstractClasses'])} abstract\"\n",
    "        )\n",
    "        for cls in info[\"classes\"][:3]:\n",
    "            sample = \", \".join(attr[\"name\"] for attr in cls[\"attributes\"][:3])\n",
    "            if not sample:\n",
    "                sample = \"no attributes\"\n",
    "            print(f\"  - {cls['name']} ({cls['attributeCount']} attrs) {sample}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b722cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched documentation for classes, attributes, and registers.\n"
     ]
    }
   ],
   "source": [
    "TARGET_DOC_TAGS = {\n",
    "    \"definition (da)\": \"definitionDa\",\n",
    "    \"example (da)\": \"exampleDa\",\n",
    "    \"comment (da)\": \"commentDa\",\n",
    "}\n",
    "\n",
    "\n",
    "def _clean_doc_text(raw: str | None) -> str | None:\n",
    "    if not raw:\n",
    "        return None\n",
    "    text = raw.replace(\"&lt;memo&gt;\", \"\").replace(\"&lt;/memo&gt;\", \"\")\n",
    "    text = text.replace(\"<memo>\", \"\").replace(\"</memo>\", \"\")\n",
    "    if \"#NOTES#\" in text:\n",
    "        text = text.split(\"#NOTES#\", 1)[1]\n",
    "    text = text.replace(\"&#xA;\", \"\\n\").strip()\n",
    "    return text or None\n",
    "\n",
    "\n",
    "def _extract_tag_bundle(tags_elem) -> dict[str, str] | None:\n",
    "    if tags_elem is None:\n",
    "        return None\n",
    "    bundle = {}\n",
    "    for tag in tags_elem:\n",
    "        tag_name = tag.attrib.get(\"name\")\n",
    "        target_key = TARGET_DOC_TAGS.get(tag_name)\n",
    "        if not target_key:\n",
    "            continue\n",
    "        value = _clean_doc_text(tag.attrib.get(\"notes\") or tag.attrib.get(\"value\"))\n",
    "        if value:\n",
    "            bundle[target_key] = value\n",
    "    return bundle or None\n",
    "\n",
    "\n",
    "def _collect_documentation(xml_path: Path) -> dict[str, dict[str, str]]:\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    extension = None\n",
    "    for elem in root:\n",
    "        if _tag_name(elem) == \"Extension\":\n",
    "            extension = elem\n",
    "            break\n",
    "    if extension is None:\n",
    "        return {}\n",
    "    elements_container = None\n",
    "    for child in extension:\n",
    "        if _tag_name(child) == \"elements\":\n",
    "            elements_container = child\n",
    "            break\n",
    "    if elements_container is None:\n",
    "        return {}\n",
    "\n",
    "    doc_map: dict[str, dict[str, str]] = {}\n",
    "    for element in elements_container:\n",
    "        elem_id = _attr(element, \"idref\") or _attr(element, \"id\")\n",
    "        if not elem_id:\n",
    "            continue\n",
    "        tag_node = next((child for child in element if _tag_name(child) == \"tags\"), None)\n",
    "        element_doc = _extract_tag_bundle(tag_node)\n",
    "        if element_doc:\n",
    "            doc_map[elem_id] = element_doc\n",
    "        for child in element:\n",
    "            if _tag_name(child) != \"attributes\":\n",
    "                continue\n",
    "            for attr_elem in child:\n",
    "                attr_id = _attr(attr_elem, \"idref\") or _attr(attr_elem, \"id\")\n",
    "                if not attr_id:\n",
    "                    continue\n",
    "                attr_tags = next((gc for gc in attr_elem if _tag_name(gc) == \"tags\"), None)\n",
    "                attr_doc = _extract_tag_bundle(attr_tags)\n",
    "                if attr_doc:\n",
    "                    doc_map[attr_id] = attr_doc\n",
    "    return doc_map\n",
    "\n",
    "\n",
    "summary_path = Path(xmlfolder) / \"class_summary.json\"\n",
    "if not summary_path.exists():\n",
    "    raise FileNotFoundError(f\"Summary not found, run the previous cell first: {summary_path}\")\n",
    "\n",
    "data = json.loads(summary_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "for register_name, register_info in data.items():\n",
    "    xml_file = register_info.get(\"xmlFile\")\n",
    "    if not xml_file:\n",
    "        continue\n",
    "    xml_path = Path(xmlfolder) / register_name / xml_file\n",
    "    if not xml_path.exists():\n",
    "        print(f\"Missing XML for {register_name}, skipping descriptions\")\n",
    "        continue\n",
    "    doc_map = _collect_documentation(xml_path)\n",
    "    register_pkg = register_info.get(\"registerPackage\") or {}\n",
    "    register_pkg_id = register_pkg.get(\"id\") if isinstance(register_pkg, dict) else None\n",
    "    if register_pkg_id and register_pkg_id in doc_map:\n",
    "        register_info[\"registerDocumentation\"] = doc_map[register_pkg_id]\n",
    "    for cls in register_info.get(\"classes\", []):\n",
    "        cls_doc = doc_map.get(cls.get(\"id\"))\n",
    "        if cls_doc:\n",
    "            cls[\"documentation\"] = cls_doc\n",
    "        for bucket in (\"ownAttributes\", \"inheritedAttributes\", \"attributes\"):\n",
    "            for attr in cls.get(bucket, []):\n",
    "                attr_doc = doc_map.get(attr.get(\"id\"))\n",
    "                if attr_doc:\n",
    "                    attr[\"documentation\"] = attr_doc\n",
    "\n",
    "summary_path.write_text(\n",
    "    json.dumps(data, ensure_ascii=False, indent=2),\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(\"Enriched documentation for classes, attributes, and registers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "113aef4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated foreign keys for 787 attributes across 12 registers\n",
      "  - BygningerOgBoliger: 84\n",
      "  - CentraleVirksomhedsregister: 256\n",
      "  - DAGI: 64\n",
      "  - DanmarksAdresser: 34\n",
      "  - Ejendomsbeliggenhed: 8\n",
      "  - Ejendomsvurdering: 16\n",
      "  - Ejerfortegnelsen: 64\n",
      "  - GeoDanmark: 12\n",
      "  - Matrikel: 100\n",
      "  - Person: 107\n",
      "  - SkatteforvaltningensVirksomhedsregister: 26\n",
      "  - Stednavne: 16\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "summary_path = Path(xmlfolder) / \"class_summary.json\"\n",
    "if not summary_path.exists():\n",
    "    raise FileNotFoundError(f\"Summary not found, run the previous cell first: {summary_path}\")\n",
    "\n",
    "data = json.loads(summary_path.read_text(encoding=\"utf-8\"))\n",
    "class_index: dict[str, dict[str, str | None]] = {}\n",
    "for register_name, register_info in data.items():\n",
    "    for cls in register_info.get(\"classes\", []):\n",
    "        class_index[cls.get(\"id\")] = {\n",
    "            \"register\": register_name,\n",
    "            \"className\": cls.get(\"name\"),\n",
    "            \"registerXml\": register_info.get(\"xmlFile\"),\n",
    "        }\n",
    "\n",
    "def _enrich_attribute(attr: dict) -> bool:\n",
    "    if not attr.get(\"isForeignKey\"):\n",
    "        attr.pop(\"foreignKeyTarget\", None)\n",
    "        return False\n",
    "    target_id = attr.get(\"typeId\")\n",
    "    target_meta = class_index.get(target_id)\n",
    "    if target_meta:\n",
    "        attr[\"foreignKeyTarget\"] = {\n",
    "            \"classId\": target_id,\n",
    "            \"className\": target_meta.get(\"className\"),\n",
    "            \"register\": target_meta.get(\"register\"),\n",
    "            \"registerXml\": target_meta.get(\"registerXml\"),\n",
    "        }\n",
    "    else:\n",
    "        attr[\"foreignKeyTarget\"] = {\n",
    "            \"classId\": target_id,\n",
    "            \"className\": attr.get(\"typeName\"),\n",
    "            \"register\": None,\n",
    "            \"registerXml\": None,\n",
    "        }\n",
    "    return True\n",
    "\n",
    "fk_counts = defaultdict(int)\n",
    "for register_name, register_info in data.items():\n",
    "    for cls in register_info.get(\"classes\", []):\n",
    "        for bucket in (\"ownAttributes\", \"inheritedAttributes\", \"attributes\"):\n",
    "            for attr in cls.get(bucket, []):\n",
    "                if _enrich_attribute(attr):\n",
    "                    fk_counts[register_name] += 1\n",
    "\n",
    "summary_path.write_text(\n",
    "    json.dumps(data, ensure_ascii=False, indent=2),\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(\n",
    "    f\"Annotated foreign keys for {sum(fk_counts.values())} attributes across \"\n",
    "    f\"{len([k for k in fk_counts if fk_counts[k]])} registers\"\n",
    ")\n",
    "for register_name, count in sorted(fk_counts.items()):\n",
    "    if count:\n",
    "        print(f\"  - {register_name}: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semanticGIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
