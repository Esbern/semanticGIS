{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e3f0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlhome = \"https://grunddatamodel.datafordeler.dk/domaenemodeller/\"\n",
    "xmlfolder = \"/Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b64800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No XML versions found for root, skipping.\n",
      "Downloaded 2.4.2_BygningerOgBoliger.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/BygningerOgBoliger/2.4.2_BygningerOgBoliger.xml\n",
      "Downloaded 2.2.0_CentraleVirksomhedsregister.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/CentraleVirksomhedsregister/2.2.0_CentraleVirksomhedsregister.xml\n",
      "Downloaded 2.0.0_DAGI.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/DAGI/2.0.0_DAGI.xml\n",
      "Downloaded 2.0.2_DanmarksAdresser.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/DanmarksAdresser/2.0.2_DanmarksAdresser.xml\n",
      "Downloaded 1.2.1_DHMOprindelse.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/DHMOprindelse/1.2.1_DHMOprindelse.xml\n",
      "Downloaded 1.3.0_Ejendomsbeliggenhed.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Ejendomsbeliggenhed/1.3.0_Ejendomsbeliggenhed.xml\n",
      "Downloaded 1.1.3_Ejendomsvurdering.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Ejendomsvurdering/1.1.3_Ejendomsvurdering.xml\n",
      "Downloaded 1.3.2_Ejerfortegnelsen.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Ejerfortegnelsen/1.3.2_Ejerfortegnelsen.xml\n",
      "Downloaded 1.0.6_Fikspunkt.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Fikspunkter/1.0.6_Fikspunkt.xml\n",
      "Downloaded 2.0.1_GeoDanmark.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/GeoDanmark/2.0.1_GeoDanmark.xml\n",
      "Downloaded 1.0.0_Grunddata.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/GrunddataTyper/1.0.0_Grunddata.xml\n",
      "Downloaded 1.1.2_HistoriskeKortbladsinddelinger.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/HistoriskeKortbladsinddelinger/1.1.2_HistoriskeKortbladsinddelinger.xml\n",
      "Downloaded 1.0.1_Højdekurver.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Højdekurver/1.0.1_Højdekurver.xml\n",
      "Downloaded 2.0.1_Matrikel.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Matrikel/2.0.1_Matrikel.xml\n",
      "Downloaded 2.1.1_Person.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Person/2.1.1_Person.xml\n",
      "Downloaded 1.0.0_SkatteforvaltningensVirksomhedsregister.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/SkatteforvaltningensVirksomhedsregister/1.0.0_SkatteforvaltningensVirksomhedsregister.xml\n",
      "Downloaded 1.0.1_Stednavne.xml to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/Stednavne/1.0.1_Stednavne.xml\n",
      "Fetched latest XML for 17 registers.\n"
     ]
    }
   ],
   "source": [
    "from html.parser import HTMLParser\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin, unquote\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "\n",
    "class _LinkCollector(HTMLParser):\n",
    "    \"\"\"Collects href targets from the simple directory listings.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.links: list[str] = []\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag != \"a\":\n",
    "            return\n",
    "        href = dict(attrs).get(\"href\")\n",
    "        if href:\n",
    "            self.links.append(href)\n",
    "\n",
    "\n",
    "def _list_links(url: str) -> list[str]:\n",
    "    with urlopen(url) as response:\n",
    "        html = response.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "    parser = _LinkCollector()\n",
    "    parser.feed(html)\n",
    "    return parser.links\n",
    "\n",
    "\n",
    "def _version_key(filename: str):\n",
    "    name = Path(filename).name\n",
    "    if not name.lower().endswith(\".xml\") or \"_\" not in name:\n",
    "        return None\n",
    "    version_candidate = name.split(\"_\", 1)[0]\n",
    "    if not re.fullmatch(r\"\\d+(?:\\.\\d+)*\", version_candidate):\n",
    "        return None\n",
    "    return tuple(int(part) for part in version_candidate.split(\".\"))\n",
    "\n",
    "\n",
    "def _latest_xml(register_url: str):\n",
    "    candidates = []\n",
    "    for href in _list_links(register_url):\n",
    "        if not href.lower().endswith(\".xml\") or \"?\" in href:\n",
    "            continue\n",
    "        version = _version_key(href)\n",
    "        if version is None:\n",
    "            continue\n",
    "        candidates.append((version, href))\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda item: item[0], reverse=True)\n",
    "    return candidates[0][1]\n",
    "\n",
    "\n",
    "base_url = xmlhome.rstrip(\"/\") + \"/\"\n",
    "output_root = Path(xmlfolder)\n",
    "output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "register_dirs = [\n",
    "    href for href in _list_links(base_url) if href.endswith(\"/\") and href not in {\"../\", \"./\"}\n",
    " ]\n",
    "\n",
    "completed = []\n",
    "for href in register_dirs:\n",
    "    register_url = urljoin(base_url, href)\n",
    "    decoded_href = unquote(href.strip(\"/\"))\n",
    "    register_name = Path(decoded_href).name or \"root\"\n",
    "    try:\n",
    "        latest_file = _latest_xml(register_url)\n",
    "    except Exception as exc:\n",
    "        print(f\"Failed to inspect {register_name}: {exc}\")\n",
    "        continue\n",
    "    if not latest_file:\n",
    "        print(f\"No XML versions found for {register_name}, skipping.\")\n",
    "        continue\n",
    "    download_url = urljoin(register_url, latest_file)\n",
    "    destination_dir = output_root / register_name\n",
    "    destination_dir.mkdir(parents=True, exist_ok=True)\n",
    "    file_name = unquote(Path(latest_file).name)\n",
    "    destination_path = destination_dir / file_name\n",
    "    try:\n",
    "        with urlopen(download_url) as response:\n",
    "            destination_path.write_bytes(response.read())\n",
    "        print(f\"Downloaded {file_name} to {destination_path}\")\n",
    "        completed.append(register_name)\n",
    "    except Exception as exc:\n",
    "        print(f\"Failed to download {register_name} ({latest_file}): {exc}\")\n",
    "\n",
    "if completed:\n",
    "    print(f\"Fetched latest XML for {len(completed)} registers.\")\n",
    "else:\n",
    "    print(\"No XML models downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2209db4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote summaries for 17 registers to /Users/holmes/local_dev/semanticGIS/tests/semantictest/xml_models/class_summary.json\n",
      "BygningerOgBoliger: 12 classes / 1 abstract\n",
      "  - BBRSag (34 attrs) sag001Byggesagsnummer, sag002Byggesagsdato, sag003Byggetilladelsesdato\n",
      "  - Bygning (90 attrs) byg007Bygningsnummer, byg021BygningensAnvendelse, byg024AntalLejlighederMedKøkken\n",
      "  - Bygværkselement (12 attrs) forretningshændelse, forretningsområde, status\n",
      "\n",
      "CentraleVirksomhedsregister: 0 classes / 0 abstract\n",
      "\n",
      "DAGI: 54 classes / 1 abstract\n",
      "  - AdministrativInddeling (11 attrs) id, navn, registreringFra\n",
      "  - Afstemningsområde (17 attrs) afstemningsområdenummer, afstemningsstedNavn, afstemningsstedAdresse\n",
      "  - Afstemningsområde_2000000 (17 attrs) afstemningsområdenummer, afstemningsstedNavn, afstemningsstedAdresse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def _tag_name(elem):\n",
    "    tag = elem.tag\n",
    "    if isinstance(tag, str):\n",
    "        if tag.startswith(\"{\") and \"}\" in tag:\n",
    "            return tag.split(\"}\", 1)[1]\n",
    "        if \":\" in tag:\n",
    "            return tag.split(\":\", 1)[1]\n",
    "    return tag\n",
    "\n",
    "\n",
    "def _attr(elem, name):\n",
    "    if name in elem.attrib:\n",
    "        return elem.attrib[name]\n",
    "    for key, value in elem.attrib.items():\n",
    "        if key.endswith(name):\n",
    "            return value\n",
    "        if \"}\" in key and key.split(\"}\", 1)[1] == name:\n",
    "            return value\n",
    "        if \":\" in key and key.split(\":\", 1)[1] == name:\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "\n",
    "def _xmi_type(elem):\n",
    "    return (\n",
    "        elem.attrib.get(\"{http://www.omg.org/spec/XMI/20131001}type\")\n",
    "        or elem.attrib.get(\"xmi:type\")\n",
    "    )\n",
    "\n",
    "\n",
    "def _index_elements(root):\n",
    "    index = {}\n",
    "    for elem in root.iter():\n",
    "        elem_id = _attr(elem, \"id\")\n",
    "        if not elem_id or elem_id in index:\n",
    "            continue\n",
    "        index[elem_id] = {\n",
    "            \"name\": elem.attrib.get(\"name\"),\n",
    "            \"umlType\": elem.attrib.get(\"UMLType\")\n",
    "            or elem.attrib.get(\"umlType\")\n",
    "            or _xmi_type(elem)\n",
    "            or _tag_name(elem),\n",
    "            \"xmiType\": _xmi_type(elem),\n",
    "            \"tag\": _tag_name(elem),\n",
    "        }\n",
    "    return index\n",
    "\n",
    "\n",
    "def _version_tuple(filename: str) -> tuple[int, ...]:\n",
    "    candidate = Path(filename).stem.split(\"_\", 1)[0]\n",
    "    parts = []\n",
    "    for part in candidate.split(\".\"):\n",
    "        if not part.isdigit():\n",
    "            return ()\n",
    "        parts.append(int(part))\n",
    "    return tuple(parts)\n",
    "\n",
    "\n",
    "def _parse_attributes(class_elem, class_name, id_index):\n",
    "    attrs = []\n",
    "    for child in class_elem:\n",
    "        if _tag_name(child) != \"ownedAttribute\":\n",
    "            continue\n",
    "        attr_name = child.attrib.get(\"name\")\n",
    "        if not attr_name:\n",
    "            continue\n",
    "        attr_kind = _xmi_type(child) or _tag_name(child)\n",
    "        type_ref = child.attrib.get(\"type\") or _attr(child, \"type\")\n",
    "        lower = child.attrib.get(\"lower\")\n",
    "        upper = child.attrib.get(\"upper\")\n",
    "        for grandchild in child:\n",
    "            tag = _tag_name(grandchild)\n",
    "            if tag == \"lowerValue\":\n",
    "                lower = grandchild.attrib.get(\"value\")\n",
    "            elif tag == \"upperValue\":\n",
    "                upper = grandchild.attrib.get(\"value\")\n",
    "            elif tag == \"type\":\n",
    "                type_ref = (\n",
    "                    _attr(grandchild, \"idref\")\n",
    "                    or grandchild.attrib.get(\"href\")\n",
    "                    or grandchild.attrib.get(\"value\")\n",
    "                    or type_ref\n",
    "                )\n",
    "        type_meta = id_index.get(type_ref or \"\")\n",
    "        type_name = type_meta.get(\"name\") if type_meta else None\n",
    "        type_uml = None\n",
    "        if type_meta:\n",
    "            type_uml = (\n",
    "                type_meta.get(\"umlType\")\n",
    "                or type_meta.get(\"xmiType\")\n",
    "                or type_meta.get(\"tag\")\n",
    "            )\n",
    "        lower_disp = lower if lower not in (None, \"\") else \"0\"\n",
    "        upper_disp = upper if upper not in (None, \"\", \"-1\") else \"*\"\n",
    "        attrs.append(\n",
    "            {\n",
    "                \"name\": attr_name,\n",
    "                \"sourceClass\": class_name,\n",
    "                \"typeId\": type_ref,\n",
    "                \"typeName\": type_name,\n",
    "                \"typeUml\": type_uml,\n",
    "                \"type\": attr_kind,\n",
    "                \"lowerMultiplicity\": lower_disp,\n",
    "                \"upperMultiplicity\": upper_disp,\n",
    "                \"cardinality\": f\"{lower_disp}..{upper_disp}\",\n",
    "            }\n",
    "        )\n",
    "    return attrs\n",
    "\n",
    "\n",
    "def _dedup_attributes(attributes):\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for attr in attributes:\n",
    "        key = (attr[\"name\"], attr.get(\"sourceClass\"))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        ordered.append(dict(attr))\n",
    "    return ordered\n",
    "\n",
    "\n",
    "def _collect_inherited(class_id, classes, memo, stack=None):\n",
    "    # Walk the generalization tree to gather inherited attributes once per class.\n",
    "    if class_id in memo:\n",
    "        return [dict(attr) for attr in memo[class_id]]\n",
    "    if stack is None:\n",
    "        stack = set()\n",
    "    if class_id in stack:\n",
    "        return []\n",
    "    stack.add(class_id)\n",
    "    inherited = []\n",
    "    for parent_id in classes.get(class_id, {}).get(\"parents\", []):\n",
    "        parent = classes.get(parent_id)\n",
    "        if not parent:\n",
    "            continue\n",
    "        inherited.extend(dict(attr) for attr in parent[\"ownAttributes\"])\n",
    "        inherited.extend(_collect_inherited(parent_id, classes, memo, stack))\n",
    "    stack.remove(class_id)\n",
    "    memo[class_id] = _dedup_attributes(inherited)\n",
    "    return [dict(attr) for attr in memo[class_id]]\n",
    "\n",
    "\n",
    "def _summarize_collection(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    id_index = _index_elements(root)\n",
    "\n",
    "    classes = {}\n",
    "    for elem in root.iter():\n",
    "        if _tag_name(elem) != \"packagedElement\":\n",
    "            continue\n",
    "        if _xmi_type(elem) != \"uml:Class\":\n",
    "            continue\n",
    "        class_id = _attr(elem, \"id\")\n",
    "        if not class_id:\n",
    "            continue\n",
    "        class_name = elem.attrib.get(\"name\") or class_id\n",
    "        parents = []\n",
    "        for child in elem:\n",
    "            if _tag_name(child) == \"generalization\":\n",
    "                parent_id = _attr(child, \"general\")\n",
    "                if parent_id:\n",
    "                    parents.append(parent_id)\n",
    "        classes[class_id] = {\n",
    "            \"name\": class_name,\n",
    "            \"isAbstract\": (_attr(elem, \"isAbstract\") or \"\").lower() in {\"true\", \"1\"},\n",
    "            \"parents\": parents,\n",
    "            \"ownAttributes\": _parse_attributes(elem, class_name, id_index),\n",
    "        }\n",
    "\n",
    "    inheritance_cache = {}\n",
    "    class_entries = []\n",
    "    for class_id, class_info in sorted(classes.items(), key=lambda item: item[1][\"name\"]):\n",
    "        inherited = _collect_inherited(class_id, classes, inheritance_cache, set())\n",
    "        own_attrs = [dict(attr) for attr in class_info[\"ownAttributes\"]]\n",
    "        all_attrs = _dedup_attributes(own_attrs + inherited)\n",
    "        class_entries.append(\n",
    "            {\n",
    "                \"name\": class_info[\"name\"],\n",
    "                \"isAbstract\": class_info[\"isAbstract\"],\n",
    "                \"ownAttributes\": own_attrs,\n",
    "                \"inheritedAttributes\": inherited,\n",
    "                \"attributes\": all_attrs,\n",
    "                \"attributeCount\": len(all_attrs),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    abstract_names = sorted(\n",
    "        class_info[\"name\"]\n",
    "        for class_info in classes.values()\n",
    "        if class_info[\"isAbstract\"]\n",
    "    )\n",
    "    return {\n",
    "        \"xmlFile\": xml_path.name,\n",
    "        \"classes\": class_entries,\n",
    "        \"abstractClasses\": abstract_names,\n",
    "    }\n",
    "\n",
    "\n",
    "root_dir = Path(xmlfolder)\n",
    "if not root_dir.exists():\n",
    "    raise FileNotFoundError(f\"XML folder not found: {root_dir}\")\n",
    "\n",
    "collection_summaries = {}\n",
    "for register_dir in sorted((p for p in root_dir.iterdir() if p.is_dir()), key=lambda p: p.name):\n",
    "    xml_files = sorted(\n",
    "        register_dir.glob(\"*.xml\"),\n",
    "        key=lambda path: (_version_tuple(path.name), path.name),\n",
    "    )\n",
    "    if not xml_files:\n",
    "        continue\n",
    "    xml_path = xml_files[-1]\n",
    "    try:\n",
    "        collection_summaries[register_dir.name] = _summarize_collection(xml_path)\n",
    "    except Exception as exc:\n",
    "        print(f\"Failed to summarize {xml_path}: {exc}\")\n",
    "\n",
    "if not collection_summaries:\n",
    "    print(f\"No XML models found under {root_dir}\")\n",
    "else:\n",
    "    summary_path = root_dir / \"class_summary.json\"\n",
    "    summary_path.write_text(\n",
    "        json.dumps(collection_summaries, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    print(f\"Wrote summaries for {len(collection_summaries)} registers to {summary_path}\")\n",
    "\n",
    "    preview_count = 3\n",
    "    for register_name in list(collection_summaries)[:preview_count]:\n",
    "        info = collection_summaries[register_name]\n",
    "        print(\n",
    "            f\"{register_name}: {len(info['classes'])} classes / \"\n",
    "            f\"{len(info['abstractClasses'])} abstract\"\n",
    "        )\n",
    "        for cls in info[\"classes\"][:3]:\n",
    "            sample = \", \".join(attr[\"name\"] for attr in cls[\"attributes\"][:3])\n",
    "            if not sample:\n",
    "                sample = \"no attributes\"\n",
    "            print(f\"  - {cls['name']} ({cls['attributeCount']} attrs) {sample}\")\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semanticGIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
